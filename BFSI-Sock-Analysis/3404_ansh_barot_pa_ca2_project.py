# -*- coding: utf-8 -*-
"""3404_Ansh_Barot_PA_CA2_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y-2wPpXz27B2voM4REAx2T4o6isV2nMk
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('/content/3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv')
df.head()

df.info()

df.describe()

df['Open Price'] = pd.to_numeric(df['Open Price'], errors='coerce')
df['Close Price'] = pd.to_numeric(df['Close Price'], errors='coerce')
df['PE Ratio'] = pd.to_numeric(df['PE Ratio'], errors='coerce')

df.info()

# Calculate the descriptive statistics
trading_vol_mean = df['Trading Volume (In Millions)'].mean()
trading_vol_median = df['Trading Volume (In Millions)'].median()
trading_vol_mode = df['Trading Volume (In Millions)'].mode()[0]
trading_vol_std = df['Trading Volume (In Millions)'].std()
trading_vol_var = df['Trading Volume (In Millions)'].var()
trading_vol_min = df['Trading Volume (In Millions)'].min()
trading_vol_max = df['Trading Volume (In Millions)'].max()
trading_vol_range = trading_vol_max - trading_vol_min
trading_vol_skew = df['Trading Volume (In Millions)'].skew()
trading_vol_kurt = df['Trading Volume (In Millions)'].kurtosis()

# Create a DataFrame for the numerical analysis results
numerical_analysis = pd.DataFrame({
    'Metric': ['Mean', 'Median', 'Mode', 'Standard Deviation', 'Variance', 'Range', 'Minimum', 'Maximum', 'Skewness', 'Kurtosis'],
    'Value': [trading_vol_mean, trading_vol_median, trading_vol_mode, trading_vol_std, trading_vol_var, trading_vol_range,
              trading_vol_min, trading_vol_max,trading_vol_skew, trading_vol_kurt]
})

# Print the numerical analysis results.
print("Univariate Analysis for 'Trading Volume (In Millions)' (Numerical):")
print(numerical_analysis.to_markdown(index=False, numalign="left", stralign="left"))

# Convert 'Publication Date' to a new 'Decade' column
df['Decade'] = (df['Publication Date'] // 10 * 10).astype(str) + 's'

# Count the number of stocks published in each decade
decade_counts = df['Decade'].value_counts().sort_index()

# Convert the Series to a DataFrame for better display
decade_counts_df = decade_counts.reset_index()
decade_counts_df.columns = ['Decade', 'Number of Stocks']

# Print the final result in a clear, formatted table
print(decade_counts_df.to_markdown(index=False, numalign="left", stralign="left"))

# --- Categorical Analysis for 'Sentiment Score Index' ---

# Get the frequency counts of each sentiment score.
sentiment_counts = df['Sentiment Score Index'].value_counts().reset_index()
sentiment_counts.columns = ['Sentiment', 'Frequency']

# Calculate the proportion (percentage) of each sentiment.
sentiment_counts['Percentage'] = (sentiment_counts['Frequency'] / len(df)) * 100

# Print the categorical analysis results.
print("\nUnivariate Analysis for 'Sentiment Score Index' (Categorical):")
print(sentiment_counts.to_markdown(index=False, numalign="left", stralign="left"))

# --- Plot 1: Distribution of stocks across different industries ---
plt.figure(figsize=(10, 6))
industry_counts = df['Stock Industry Name'].value_counts()
industry_counts.plot(kind='bar', color='skyblue')
plt.title('Distribution of Stocks Across Industries', fontsize=16, fontweight='bold')
plt.ylabel('Number of Stocks', fontsize=12)
plt.xlabel('Stock Industry Name', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('industry_distribution.png')
plt.close()

# --- Plot 2: Distribution of sentiment (Bear, Bull, Neutral) ---
plt.figure(figsize=(8, 8))
# Clean the data by correcting spelling errors
df['Sentiment Score Index'] = df['Sentiment Score Index'].replace({'Neurtal': 'Neutral', 'Bulli': 'Bull'})
sentiment_counts = df['Sentiment Score Index'].value_counts()
plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90, colors=['lightcoral', 'gold', 'lightgreen'])
plt.title('Sentiment Distribution Among Stocks', fontsize=16, fontweight='bold')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.tight_layout()
plt.savefig('sentiment_distribution.png')
plt.close()

# --- Plot 3: Volatility distribution across all stocks ---
plt.figure(figsize=(10, 6))
plt.hist(df['Volatility (In Rupees)'], bins=10, color='lightgreen', edgecolor='black')
plt.title('Volatility Distribution Across All Stocks', fontsize=16, fontweight='bold')
plt.xlabel('Volatility (In Rupees)', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('volatility_distribution.png')
plt.close()

# The 'PE Ratio' column is an object, so we need to clean and convert it to a numeric type.
df['PE Ratio'] = df['PE Ratio'].astype(str).str.replace(',', '', regex=False).str.replace('â€“', '-', regex=False)
df['PE Ratio'] = pd.to_numeric(df['PE Ratio'], errors='coerce')

# Drop rows where 'PE Ratio' is NaN
df_cleaned = df.dropna(subset=['PE Ratio'])

# Group the data by 'Stock Industry Name' and calculate the average 'PE Ratio' for each group.
average_pe_ratio = df_cleaned.groupby('Stock Industry Name')['PE Ratio'].mean().reset_index()

# Rename the columns for clarity
average_pe_ratio.columns = ['Stock Industry Name', 'Average PE Ratio']

# Print the result in a markdown table format.
print(average_pe_ratio.to_markdown(index=False, numalign="left", stralign="left"))

# The column name for RSI is 'Relative Strength Index (In Scale of 0-100)'
# Convert the RSI column to numeric, coercing any errors
df['RSI'] = pd.to_numeric(df['Relative Strength Index (In Scale of 0-100)'], errors='coerce')

# Group the data by 'Stock Industry Name' and calculate the average RSI
average_rsi = df.groupby('Stock Industry Name')['RSI'].mean().reset_index()

# Rename the columns for clarity
average_rsi.columns = ['Stock Industry Name', 'Average RSI']

# Print the result in a markdown table format
print(average_rsi.to_markdown(index=False, numalign="left", stralign="left"))

# Select the top 10 stocks for better visualization
df_plot = df.head(10).copy()

# Set up the figure and axes
plt.figure(figsize=(15, 8))
x = np.arange(len(df_plot['Stock Name']))
width = 0.35

# Create the bars for 'Open Price' and 'Close Price'
plt.bar(x - width/2, df_plot['Open Price'], width, label='Open Price')
plt.bar(x + width/2, df_plot['Close Price'], width, label='Close Price')

# Set x-axis labels and ticks
plt.xticks(x, df_plot['Stock Name'], rotation=45, ha="right")

# Add labels and a title
plt.xlabel("Stock Name")
plt.ylabel("Price (In Rupees)")
plt.title("Comparison of Open and Close Prices for Top 10 Stocks")
plt.legend()
plt.tight_layout()

# Save the plot
plt.savefig("open_close_price_comparison.png")

print("\nUpdated DataFrame info:")
df.info()
print("\nFirst few rows of cleaned data:")
print(df_plot[['Stock Name', 'Open Price', 'Close Price']].head())

# Sort the DataFrame by 'Trading Volume (In Millions)' in descending order
try:
    df_sorted_volume = df.sort_values(by='Trading Volume (In Millions)', ascending=False)
except KeyError as e:
    print(f"Error: The column {e} was not found in the dataset.")
    exit()

# Create a horizontal bar chart for better readability of stock names
plt.figure(figsize=(15, 20))  # Adjusting figure size for better label visibility
plt.barh(df_sorted_volume['Stock Name'], df_sorted_volume['Trading Volume (In Millions)'])
plt.xlabel("Trading Volume (In Millions)")
plt.ylabel("Stock Name")
plt.title("Trading Volume of Stocks (Sorted)")
plt.tight_layout()

# Save the plot
plt.savefig("trading_volume_horizontal_bar_chart.png")

print("Horizontal bar chart with clearer labels saved.")

# Calculate the 'Price Change'
df['Price Change'] = df['Close Price'] - df['Open Price']

# Sort the DataFrame by 'Price Change' for better visualization
df_sorted = df.sort_values(by='Price Change', ascending=False)

# Create a horizontal bar chart
plt.figure(figsize=(15, 20))
colors = np.where(df_sorted['Price Change'] > 0, 'green', 'red')
plt.barh(df_sorted['Stock Name'], df_sorted['Price Change'], color=colors)

# Add labels and a title
plt.xlabel("Price Change (Close - Open)")
plt.ylabel("Stock Name")
plt.title("Stock Price Change from Open to Close")
plt.tight_layout()

# Save the plot
plt.savefig("price_change_bar_chart.png")

print("\nDataFrame with Price Change column:")
print(df_sorted[['Stock Name', 'Open Price', 'Close Price', 'Price Change']].head())
print("\nDataFrame info after creating 'Price Change' column:")
df.info()

# Create the box plot with three different colors
try:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x='Sentiment Score Index', y='Volatility (In Rupees)', data=df, hue='Sentiment Score Index', palette='Paired')
    plt.title('Volatility by Sentiment Score Index')
    plt.xlabel('Sentiment Score Index')
    plt.ylabel('Volatility (In Rupees)')
    plt.grid(axis='y')
    plt.tight_layout()

    # Save the plot
    plt.savefig("volatility_by_sentiment_boxplot_colored.png")
except KeyError as e:
    print(f"Error: One of the required columns, {e}, was not found in the dataset.")
    exit()

#Question 1
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
file_path = "3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv"
df = pd.read_csv(file_path)

# Inspect the data
print("Initial DataFrame head:")
print(df.head())
print("\nInitial DataFrame info:")
df.info()

# Clean 'PE Ratio' and other relevant columns
try:
    df['PE Ratio'] = df['PE Ratio'].astype(str).str.replace(',', '', regex=False)
    df['PE Ratio'] = pd.to_numeric(df['PE Ratio'], errors='coerce')

    df['Relative Strength Index (In Scale of 0-100)'] = pd.to_numeric(
        df['Relative Strength Index (In Scale of 0-100)'], errors='coerce'
    )
    df['Volatility (In Rupees)'] = pd.to_numeric(
        df['Volatility (In Rupees)'], errors='coerce'
    )
except KeyError as e:
    print(f"Error: The column {e} was not found in the dataset.")
    exit()

# Drop rows with NaN values in the relevant columns
df.dropna(
    subset=[
        'PE Ratio',
        'Relative Strength Index (In Scale of 0-100)',
        'Volatility (In Rupees)',
    ],
    inplace=True,
)
# Question 1
# Create scatter plots
plt.style.use('seaborn-v0_8-whitegrid')

# Scatter plot for PE Ratio vs. RSI
plt.figure(figsize=(10, 6))
sns.scatterplot(
    x='PE Ratio',
    y='Relative Strength Index (In Scale of 0-100)',
    data=df,
    color='blue',
)
plt.title('P/E Ratio vs. Relative Strength Index (RSI)')
plt.xlabel('P/E Ratio')
plt.ylabel('Relative Strength Index (RSI)')
plt.savefig('pe_ratio_vs_rsi_scatter.png')
plt.show()

# Scatter plot for PE Ratio vs. Volatility
plt.figure(figsize=(10, 6))
sns.scatterplot(x='PE Ratio', y='Volatility (In Rupees)', data=df, color='red')
plt.title('P/E Ratio vs. Volatility')
plt.xlabel('P/E Ratio')
plt.ylabel('Volatility (In Rupees)')
plt.savefig('pe_ratio_vs_volatility_scatter.png')
plt.show()

# Create and visualize the correlation matrix
corr_df = df[
    [
        'PE Ratio',
        'Relative Strength Index (In Scale of 0-100)',
        'Volatility (In Rupees)',
    ]
].corr()

plt.figure(figsize=(8, 6))
sns.heatmap(corr_df, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of P/E Ratio, RSI, and Volatility')
plt.tight_layout()
plt.savefig('correlation_matrix_heatmap.png')
plt.show()

print("\nUpdated DataFrame info:")
df.info()
print("\nCorrelation matrix calculated and visualized.")

import pandas as pd

# Load the dataset
file_path = "3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv"
df = pd.read_csv(file_path)

# Inspect the data
print("Initial DataFrame head:")
print(df.head())
print("\nInitial DataFrame info:")
df.info()

# Define the numerical mapping for sentiment scores
sentiment_mapping = {'Bull': 1, 'Neutral': 0, 'Bear': -1}

# Convert 'Sentiment Score Index' to a new numerical column
try:
    df['Sentiment Score Numeric'] = df['Sentiment Score Index'].map(sentiment_mapping)
except KeyError as e:
    print(f"Error: The column {e} was not found in the dataset.")
    exit()

# Group by 'Business Model Type' and calculate the mean of the new numeric sentiment score
average_sentiment = df.groupby('Business Model Type')['Sentiment Score Numeric'].mean().sort_values(ascending=False)

print("\nAverage Sentiment Score by Business Model Type:")
print(average_sentiment)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
file_path = "3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv"
df = pd.read_csv(file_path)

# Inspect the data
print("Initial DataFrame head:")
print(df.head())
print("\nInitial DataFrame info:")
df.info()

# Clean and ensure relevant columns are numeric
try:
    df['Trading Volume (In Millions)'] = pd.to_numeric(df['Trading Volume (In Millions)'], errors='coerce')
    df['Volatility (In Rupees)'] = pd.to_numeric(df['Volatility (In Rupees)'], errors='coerce')
except KeyError as e:
    print(f"Error: The column {e} was not found in the dataset.")
    exit()

# Drop any rows with NaN values in the relevant columns
df.dropna(subset=['Trading Volume (In Millions)', 'Volatility (In Rupees)'], inplace=True)

# Create the scatter plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Trading Volume (In Millions)', y='Volatility (In Rupees)', data=df)
plt.title('Relationship Between Trading Volume and Volatility')
plt.xlabel('Trading Volume (In Millions)')
plt.ylabel('Volatility (In Rupees)')
plt.grid(True)
plt.tight_layout()

# Save the plot
plt.savefig("trading_volume_vs_volatility_scatter.png")

print("\nScatter plot of Trading Volume vs. Volatility created.")
print("\nDataFrame info after cleaning:")
df.info()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import seaborn as sns

# Load the dataset
file_path = "3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv"
df = pd.read_csv(file_path)

# Select relevant features
features = ['PE Ratio', 'Relative Strength Index (In Scale of 0-100)', 'Volatility (In Rupees)']
df_cluster = df[features].copy()

# Data Cleaning and Preprocessing
try:
    df_cluster['PE Ratio'] = pd.to_numeric(df_cluster['PE Ratio'].astype(str).str.replace(',', '', regex=False), errors='coerce')
    df_cluster.dropna(subset=features, inplace=True)
except KeyError as e:
    print(f"Error: The column {e} was not found in the dataset.")
    exit()

# Scale the data
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_cluster)

# Perform K-Means clustering with 3 clusters
num_clusters = 3
kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
df_cluster['Cluster'] = kmeans.fit_predict(df_scaled)

# Dimensionality reduction for visualization using PCA
pca = PCA(n_components=2)
df_pca = pca.fit_transform(df_scaled)
df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])
df_pca['Cluster'] = df_cluster['Cluster'].values

# Visualize the clusters
plt.figure(figsize=(10, 8))
sns.scatterplot(
    x='PC1', y='PC2', hue='Cluster', data=df_pca, palette='viridis', s=100
)
plt.title('Stock Clusters (PCA-Reduced)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.grid(True)
plt.legend(title='Cluster')
plt.savefig('kmeans_clusters_2d_plot.png')
plt.show()

# Analyze cluster characteristics
cluster_summary = df_cluster.groupby('Cluster').mean()
cluster_summary_readable = pd.DataFrame(scaler.inverse_transform(cluster_summary), columns=features)
cluster_summary_readable.index.name = 'Cluster'
print("\nReadable Cluster Characteristics:")
print(cluster_summary_readable)

import pandas as pd
import numpy as np

# Load the dataset
file_path = "3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv"
df = pd.read_csv(file_path)

# Inspect the data
print("Initial DataFrame head:")
print(df.head())
print("\nInitial DataFrame info:")
df.info()

# Clean 'Close Price' and 'PE Ratio' columns and convert to float
try:
    df['Close Price'] = df['Close Price'].astype(str).str.replace(',', '', regex=False)
    df['Close Price'] = pd.to_numeric(df['Close Price'], errors='coerce')

    df['PE Ratio'] = df['PE Ratio'].astype(str).str.replace(',', '', regex=False)
    df['PE Ratio'] = pd.to_numeric(df['PE Ratio'], errors='coerce')
except KeyError as e:
    print(f"Error: The column {e} was not found in the dataset.")
    exit()

# Drop rows where 'Close Price' or 'PE Ratio' are NaN or where 'PE Ratio' is zero
df.dropna(subset=['Close Price', 'PE Ratio'], inplace=True)
df = df[df['PE Ratio'] != 0].copy()

# Calculate the performance ratio
df['Performance Ratio'] = df['Close Price'] / df['PE Ratio']

# Sort the DataFrame by the new performance ratio in descending order
df_ranked = df.sort_values(by='Performance Ratio', ascending=False)

# Display the top 10 performing stocks
print("\nTop 10 Stocks by Performance Ratio (Close Price / PE Ratio):")
print(df_ranked[['Stock Name', 'Close Price', 'PE Ratio', 'Performance Ratio']].head(10))
print("\nDataFrame info after cleaning and adding new column:")
df.info()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
file_path = "3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv"
df = pd.read_csv(file_path)

# Inspect the data
print("Initial DataFrame head:")
print(df.head())
print("\nInitial DataFrame info:")
df.info()

# Create a pivot table for the stacked bar chart
try:
    sentiment_by_industry = df.groupby('Stock Industry Name')['Sentiment Score Index'].value_counts().unstack().fillna(0)
    sentiment_by_industry = sentiment_by_industry.sort_index()

    # Create the stacked bar chart
    sentiment_by_industry.plot(kind='bar', stacked=True, figsize=(15, 8))
    plt.title('Sentiment Score Distribution by Industry')
    plt.xlabel('Stock Industry Name')
    plt.ylabel('Count of Stocks')
    plt.xticks(rotation=90, ha='center')
    plt.legend(title='Sentiment Score Index')
    plt.tight_layout()

    # Save the plot
    plt.savefig("sentiment_by_industry_stacked_bar.png")

except KeyError as e:
    print(f"Error: The column {e} was not found in the dataset.")
    exit()

print("\nStacked bar chart of Sentiment by Industry created.")
print("\nCounts of sentiment by industry:")
print(sentiment_by_industry.head())

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Load the dataset
file_path = "3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv"
df = pd.read_csv(file_path)

# Inspect the data
print("Initial DataFrame head:")
print(df.head())
print("\nInitial DataFrame info:")
df.info()

# Data Cleaning and Preprocessing
try:
    df['PE Ratio'] = df['PE Ratio'].astype(str).str.replace(',', '', regex=False)
    df['PE Ratio'] = pd.to_numeric(df['PE Ratio'], errors='coerce')

    df['Publication Date'] = pd.to_numeric(df['Publication Date'], errors='coerce')
except KeyError as e:
    print(f"Error: The column {e} was not found in the dataset.")
    exit()

# Drop rows with NaN values in the relevant columns
df.dropna(subset=['PE Ratio', 'Publication Date'], inplace=True)

# Create a scatter plot with a trend line
plt.figure(figsize=(12, 8))
sns.regplot(
    x='Publication Date',
    y='PE Ratio',
    data=df,
    scatter_kws={'alpha': 0.6},
    line_kws={'color': 'red'},
)
plt.title('Relationship between Publication Year and P/E Ratio')
plt.xlabel('Publication Year')
plt.ylabel('P/E Ratio')
plt.grid(True)
plt.tight_layout()

# Save the plot
plt.savefig("publication_year_vs_pe_ratio.png")

print("\nScatter plot with trend line created.")
print("\nDataFrame info after cleaning:")
df.info()

import pandas as pd
import numpy as np

# Load the dataset
file_path = "3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv"
df = pd.read_csv(file_path)

# Inspect the data
print("Initial DataFrame head:")
print(df.head())
print("\nInitial DataFrame info:")
df.info()

# Clean and ensure relevant columns are numeric
try:
    df['Volatility (In Rupees)'] = pd.to_numeric(df['Volatility (In Rupees)'], errors='coerce')
    df['Relative Strength Index (In Scale of 0-100)'] = pd.to_numeric(df['Relative Strength Index (In Scale of 0-100)'], errors='coerce')
except KeyError as e:
    print(f"Error: The column {e} was not found in the dataset.")
    exit()

# Drop rows with NaN values in the relevant columns
df.dropna(subset=['Volatility (In Rupees)', 'Relative Strength Index (In Scale of 0-100)', 'Stock Industry Name'], inplace=True)

# Group by 'Stock Industry Name' and calculate the mean of both metrics
industry_averages = df.groupby('Stock Industry Name')[['Volatility (In Rupees)', 'Relative Strength Index (In Scale of 0-100)']].mean()

# Calculate the combined average
industry_averages['Combined Average'] = industry_averages['Volatility (In Rupees)'] + industry_averages['Relative Strength Index (In Scale of 0-100)']

# Sort the results in descending order by the combined average
sorted_industries = industry_averages.sort_values(by='Combined Average', ascending=False)

# Display the top 10 industries
print("\nTop 10 Industries by Combined Average of Volatility and RSI:")
print(sorted_industries.head(10))

# Print info about the cleaned DataFrame
print("\nDataFrame info after cleaning:")
df.info()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
file_path = "3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv"
df = pd.read_csv(file_path)

# Inspect the data
print("Initial DataFrame head:")
print(df.head())
print("\nInitial DataFrame info:")
df.info()

# Clean and ensure relevant columns are numeric
try:
    df['Close Price'] = df['Close Price'].astype(str).str.replace(',', '', regex=False)
    df['Close Price'] = pd.to_numeric(df['Close Price'], errors='coerce')
    df['Volatility (In Rupees)'] = pd.to_numeric(df['Volatility (In Rupees)'], errors='coerce')
except KeyError as e:
    print(f"Error: The column {e} was not found in the dataset.")
    exit()

# Drop rows with NaN values in the relevant columns
df.dropna(subset=['Volatility (In Rupees)', 'Close Price'], inplace=True)

# Create the scatter plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Volatility (In Rupees)', y='Close Price', data=df)
plt.title('Risk vs. Return: Volatility vs. Close Price')
plt.xlabel('Volatility (In Rupees)')
plt.ylabel('Close Price')
plt.grid(True)
plt.tight_layout()

# Save the plot
plt.savefig("risk_vs_return_plot.png")

print("\nScatter plot of Risk vs. Return created.")
print("\nDataFrame info after cleaning:")
df.info()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Load the dataset
file_path = "3404_Ansh Barot_StockPrediction_Dataset_PA Project.csv"
try:
    df = pd.read_csv(file_path)
except FileNotFoundError:
    print(f"Error: The file '{file_path}' was not found.")
    exit()

# --- Data Preprocessing ---
# Define features (X) and target (y)
# Select numerical features for the model
features = [
    'Close Price',
    'PE Ratio',
    'Trading Volume (In Millions)',
    'Relative Strength Index (In Scale of 0-100)',
    'Volatility (In Rupees)',
]
target = 'Sentiment Score Index'

# Clean and convert columns to numeric, handling potential errors
for col in features:
    try:
        # Some columns might have commas, remove them before conversion
        if df[col].dtype == 'object':
            df[col] = df[col].astype(str).str.replace(',', '', regex=False)
        df[col] = pd.to_numeric(df[col], errors='coerce')
    except KeyError:
        print(f"Error: The column '{col}' was not found in the dataset.")
        exit()

# Drop rows with any missing values in our features or target
df.dropna(subset=features + [target], inplace=True)

# Encode the categorical target variable into numerical labels
le = LabelEncoder()
df['Sentiment Score Numeric'] = le.fit_transform(df[target])

X = df[features]
y = df['Sentiment Score Numeric']

# --- Model Building and Training ---
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and train the Decision Tree Classifier
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)

# --- Feature Importance Analysis ---
# Get feature importances
importances = dt_classifier.feature_importances_
feature_names = X.columns

# Create a DataFrame for better visualization
feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)

print("\nFeature Importances:")
print(feature_importance_df)

# --- Model Evaluation (Optional but recommended) ---
y_pred = dt_classifier.predict(X_test)
accuracy = np.mean(y_pred == y_test)
print(f"\nModel Accuracy on Test Set: {accuracy:.2f}")

# --- Visualization ---
plt.style.use('seaborn-v0_8-whitegrid')

# Plotting Feature Importance
plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=feature_importance_df, palette='viridis', hue='feature', legend=False)
plt.title('Feature Importance for Sentiment Prediction')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.savefig('feature_importance_bar_chart.png')
plt.show()

print("\nDecision Tree model has been built, and feature importances have been calculated and plotted.")